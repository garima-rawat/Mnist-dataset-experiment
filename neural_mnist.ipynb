{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a88cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "53180662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, 10))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def sigmoidDer(Z):\n",
    "    return sigmoid(Z) * (1 - sigmoid(Z))\n",
    "\n",
    "def softmax(Z):\n",
    "    f_Z = np.exp(Z) / sum(np.exp(Z))\n",
    "    return f_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0a96f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "#         training_image = sys.argv[1]\n",
    "#         training_label = sys.argv[2]\n",
    "#         test_image = sys.argv[3]\n",
    "#         test_label = sys.argv[4]\n",
    "\n",
    "    training_image = 'train_image.csv'\n",
    "    training_label = 'train_label.csv'\n",
    "    test_image = 'test_image.csv'\n",
    "    test_label = 'test_label.csv'\n",
    "\n",
    "    df = pd.read_csv(training_image, header=None)\n",
    "    df['label'] = pd.read_csv(training_label, header=None)\n",
    "    df = df.loc[0:1000]\n",
    "    training_data = df\n",
    "\n",
    "    df = pd.read_csv(test_image, header=None)\n",
    "    df['label'] = pd.read_csv(test_label, header=None)\n",
    "    test_data = df\n",
    "    \n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f6fe34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, hidden_layers=1):\n",
    "        self.weights = [0,0]\n",
    "        self.weights[0] = np.random.rand(16, 784) - 0.5\n",
    "        self.weights[1] = np.random.rand(10, 16) - 0.5\n",
    "        \n",
    "        self.bias = [0,0]\n",
    "        self.bias[0] = np.random.rand(16,1) - 0.5\n",
    "        self.bias[1] = np.random.rand(10,1) - 0.5\n",
    "\n",
    "        self.act = [0,0]\n",
    "        self.act[0] ##input array\n",
    "        self.act[1] \n",
    "        \n",
    "        self.W1 = np.random.rand(16, 784) - 0.5\n",
    "        self.b1 = np.random.rand(16, 1) - 0.5\n",
    "        self.W2 = np.random.rand(10, 16) - 0.5\n",
    "        self.b2 = np.random.rand(10, 1) - 0.5\n",
    "        self.W3 = np.random.rand(10, 10) - 0.5\n",
    "        self.b3 = np.random.rand(10, 1) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "933bf6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, epochs = 50, alpha = 0.1, batch_size = 1000, hidden_layers = 1, neurons = 5):\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.neurons = neurons\n",
    "\n",
    "        self.train_accuracy = [0]*(epochs+1)\n",
    "        self.test_accuracy = [0]*(epochs+1)\n",
    "        self.model = Model(hidden_layers)\n",
    "    \n",
    "    def init_data(self, training_data, test_data):\n",
    "        self.training_data, self.test_data = training_data, test_data\n",
    "    \n",
    "    def accuracy(self, i):\n",
    "        \"\"\"\n",
    "        input X and y of train and test data and outputs accuracy\n",
    "        Note : the y value for each instance is a single predicted number instead of 10 length array storing probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"******************\\nIn accuracy\")\n",
    "        \n",
    "        \n",
    "        train_X = self.training_data.iloc[:, 0:784]\n",
    "        train_y = self.training_data['label'].to_numpy()\n",
    "        train_X = train_X.to_numpy()\n",
    "        train_X = train_X.T\n",
    "        train_X = train_X/784\n",
    "        _, _, _,_,_, A3 = self.feedForward(train_X)\n",
    "        y_pred = np.argmax(A3, 0)\n",
    "        print(y_pred)\n",
    "        print(train_y)\n",
    "        acc = np.sum(y_pred == train_y) / train_y.size\n",
    "        print(acc)\n",
    "        self.train_accuracy[i] = acc\n",
    "        \n",
    "        test_X = self.test_data.iloc[:, 0:784]\n",
    "        test_y = self.test_data['label'].to_numpy()\n",
    "        test_X = test_X.to_numpy()\n",
    "        test_X = test_X.T\n",
    "        test_X = test_X/784\n",
    "        _, _, _,_,_, A3 = self.feedForward(test_X)\n",
    "        y_pred = np.argmax(A3, 0)\n",
    "        print(y_pred)\n",
    "        print(test_y)\n",
    "        acc = np.sum(y_pred == test_y) / test_y.size\n",
    "        print(acc)\n",
    "        self.test_accuracy[i] = acc\n",
    "\n",
    "    def plot(self):\n",
    "        # Define data values\n",
    "        x = [k for k in range(self.epochs+1)]\n",
    "        y = self.train_accuracy\n",
    "        z = self.test_accuracy\n",
    "        plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "        line1, = plt.plot(y, label = \"training\")\n",
    "        line2, = plt.plot(z, label = \"test\")\n",
    "        leg = plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def feedForward(self, X):\n",
    "        \"\"\"\n",
    "        Input : X is features in the input layer as pandas Df, m is no of samples i.e. batch size or leftover\n",
    "        Algo : converts to numpy 2D Arr, \n",
    "        Outputs : probability of output layer\n",
    "        for H samples, input is H X 764 and output is H X 10\n",
    "        \"\"\"        \n",
    "        Z1 = self.model.W1.dot(X) + self.model.b1\n",
    "        A1 = sigmoid(Z1)\n",
    "        Z2 = self.model.W2.dot(A1) + self.model.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        Z3 = self.model.W3.dot(A2) + self.model.b3\n",
    "        A3 = softmax(Z3)\n",
    "        return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "    def lossFunc(self, true_y, pred_y):\n",
    "        \"\"\"\n",
    "        Takes as input numpy 2D matrix of prediction probabilities and 1D pandas DF of true_y values\n",
    "        Convert true values to 2D matrix, 1 for true value and 0 for rest\n",
    "        Matrix : for H samples H X 10\n",
    "        Algo : Mean of MSE of each sample\n",
    "        \"\"\"\n",
    "\n",
    "        #print(\"loss function\")\n",
    "        \n",
    "        n = len(true_y)\n",
    "        theta = np.empty(shape=(n, 10))\n",
    "        theta.fill(0)\n",
    "\n",
    "        true_y = true_y.to_numpy()\n",
    "        for k in range(n):\n",
    "            theta[k][true_y[k]] = 1\n",
    "\n",
    "        print(pred_y.shape, theta.shape)\n",
    "        \n",
    "        return np.square(np.subtract(pred_y, theta)).mean(1).mean()\n",
    "\n",
    "    def oneHot(self, true_y):\n",
    "\n",
    "        n = len(true_y)\n",
    "        theta = np.empty(shape=(n, 10))\n",
    "        theta.fill(0)\n",
    "\n",
    "        true_y = true_y.to_numpy()\n",
    "        for k in range(n):\n",
    "            theta[k][true_y[k]] = 1\n",
    "        return theta\n",
    "\n",
    "\n",
    "    def backPropagate(self, m, X, Y, Z1, A1, Z2, A2, Z3, A3):\n",
    "        \"\"\"\n",
    "        Takes as input a cost function value and adjusts the weights and biases of the model\n",
    "        For each batch that went through the forward pass, we backpropagate using SGD(Stochastic Gradient Descent)\n",
    "        \"\"\"\n",
    "        one_hot_Y = one_hot(Y)\n",
    "        dZ3 = A3 - one_hot_Y\n",
    "        dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "        db3 = 1 / m * np.sum(dZ3)\n",
    "        \n",
    "        dZ2 = self.model.W3.T.dot(dZ3) * sigmoidDer(Z2)\n",
    "        dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "        db2 = 1 / m * np.sum(dZ2)\n",
    "        \n",
    "        dZ1 = self.model.W2.T.dot(dZ2) * sigmoidDer(Z1)\n",
    "        dW1 = 1 / m * dZ1.dot(X.T)\n",
    "        db1 = 1 / m * np.sum(dZ1)\n",
    "        \n",
    "        self.updateParam(dW1, db1, dW2, db2, dW3, db3)\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    def updateParam(self, dW1, db1, dW2, db2, dW3, db3):\n",
    "        self.model.W1 = self.model.W1 - self.alpha * dW1\n",
    "        self.model.b1 = self.model.b1 - self.alpha * db1    \n",
    "        self.model.W2 = self.model.W2 - self.alpha * dW2  \n",
    "        self.model.b2 = self.model.b2 - self.alpha * db2\n",
    "        self.model.W3 = self.model.W3 - self.alpha * dW3  \n",
    "        self.model.b3 = self.model.b3 - self.alpha * db3 \n",
    "        \n",
    "\n",
    "    def algo(self):\n",
    "        \"\"\"\n",
    "        backbone of the algorithm\n",
    "        For each epoch, shuffles data and divides in different batches\n",
    "        For each batch, feedforward the training samples, calculate loss function and then backpropagate to change weights and biases\n",
    "        After all batches of an epoch are computed, calculate their accuracy on training and test data\n",
    "        \"\"\"       \n",
    "        for i in range (1, self.epochs+1):\n",
    "            print(\"\\nEpoch #\", i)\n",
    "            np.random.shuffle(self.training_data.values)\n",
    "            n = len(self.training_data)\n",
    "    \n",
    "            for j in range(0, n, self.batch_size):\n",
    "                #print(\"Batch #\", j)\n",
    "\n",
    "                l = min(n, j+self.batch_size)\n",
    "                m = l-j ##no of training samples in a batch\n",
    "                train_X = self.training_data.iloc[j:l, 0:784]\n",
    "                train_y = self.training_data.iloc[j:l, 784]\n",
    "                train_X = train_X.to_numpy()\n",
    "                train_X = train_X.T\n",
    "                train_X = train_X/784\n",
    "                train_y = train_y.to_numpy()\n",
    "                #print(train_X, train_y)\n",
    "                \n",
    "                Z1, A1, Z2, A2, Z3, A3 = self.feedForward(train_X)\n",
    "                self.backPropagate(m, train_X, train_y, Z1, A1, Z2, A2, Z3, A3)\n",
    "            \n",
    "                #print(j, self.model.weights)\n",
    "            self.accuracy(i)\n",
    "        #print(self.train_accuracy)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7dfc0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch # 1\n",
      "******************\n",
      "In accuracy\n",
      "[7 7 7 ... 1 7 2]\n",
      "[1 9 1 ... 3 1 2]\n",
      "0.13686313686313686\n",
      "[7 7 1 ... 2 1 1]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.1409\n",
      "\n",
      "Epoch # 2\n",
      "******************\n",
      "In accuracy\n",
      "[3 3 4 ... 4 4 4]\n",
      "[6 6 1 ... 9 4 3]\n",
      "0.13486513486513488\n",
      "[4 3 4 ... 4 4 4]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.1489\n",
      "\n",
      "Epoch # 3\n",
      "******************\n",
      "In accuracy\n",
      "[1 1 1 ... 5 4 5]\n",
      "[9 1 8 ... 9 4 5]\n",
      "0.1878121878121878\n",
      "[4 1 1 ... 1 1 1]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.178\n",
      "\n",
      "Epoch # 4\n",
      "******************\n",
      "In accuracy\n",
      "[7 7 7 ... 7 7 7]\n",
      "[7 6 0 ... 0 1 7]\n",
      "0.11688311688311688\n",
      "[7 7 7 ... 7 7 7]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.1028\n",
      "\n",
      "Epoch # 5\n",
      "******************\n",
      "In accuracy\n",
      "[9 1 1 ... 1 1 9]\n",
      "[5 1 3 ... 4 8 9]\n",
      "0.23376623376623376\n",
      "[9 1 1 ... 1 1 1]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.2442\n",
      "\n",
      "Epoch # 6\n",
      "******************\n",
      "In accuracy\n",
      "[0 0 1 ... 4 1 1]\n",
      "[6 0 7 ... 4 2 1]\n",
      "0.25674325674325676\n",
      "[7 1 1 ... 1 1 1]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.243\n",
      "\n",
      "Epoch # 7\n",
      "******************\n",
      "In accuracy\n",
      "[1 1 0 ... 1 1 0]\n",
      "[9 8 7 ... 1 6 0]\n",
      "0.2837162837162837\n",
      "[0 0 1 ... 1 1 0]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.2657\n",
      "\n",
      "Epoch # 8\n",
      "******************\n",
      "In accuracy\n",
      "[0 9 9 ... 0 1 9]\n",
      "[3 9 9 ... 3 1 9]\n",
      "0.35864135864135865\n",
      "[9 9 1 ... 9 9 4]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.335\n",
      "\n",
      "Epoch # 9\n",
      "******************\n",
      "In accuracy\n",
      "[1 1 4 ... 1 1 1]\n",
      "[9 7 9 ... 2 2 1]\n",
      "0.36063936063936064\n",
      "[7 8 1 ... 1 1 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.3499\n",
      "\n",
      "Epoch # 10\n",
      "******************\n",
      "In accuracy\n",
      "[0 4 4 ... 4 1 7]\n",
      "[0 4 9 ... 9 1 5]\n",
      "0.4435564435564436\n",
      "[7 3 1 ... 4 5 4]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.4168\n",
      "\n",
      "Epoch # 11\n",
      "******************\n",
      "In accuracy\n",
      "[4 7 1 ... 4 3 0]\n",
      "[2 9 9 ... 2 3 5]\n",
      "0.5054945054945055\n",
      "[7 3 1 ... 4 5 4]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.4845\n",
      "\n",
      "Epoch # 12\n",
      "******************\n",
      "In accuracy\n",
      "[1 5 2 ... 1 7 9]\n",
      "[1 5 2 ... 1 7 9]\n",
      "0.5404595404595405\n",
      "[7 3 1 ... 4 8 4]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.5043\n",
      "\n",
      "Epoch # 13\n",
      "******************\n",
      "In accuracy\n",
      "[1 1 1 ... 4 7 7]\n",
      "[1 1 2 ... 4 9 7]\n",
      "0.5444555444555444\n",
      "[7 3 1 ... 4 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.5176\n",
      "\n",
      "Epoch # 14\n",
      "******************\n",
      "In accuracy\n",
      "[7 0 0 ... 2 4 0]\n",
      "[9 3 0 ... 5 4 0]\n",
      "0.6113886113886113\n",
      "[7 3 1 ... 4 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.5833\n",
      "\n",
      "Epoch # 15\n",
      "******************\n",
      "In accuracy\n",
      "[3 1 0 ... 3 4 0]\n",
      "[5 1 5 ... 5 4 0]\n",
      "0.6323676323676324\n",
      "[7 8 1 ... 4 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.5933\n",
      "\n",
      "Epoch # 16\n",
      "******************\n",
      "In accuracy\n",
      "[1 2 5 ... 4 2 8]\n",
      "[1 2 5 ... 4 2 8]\n",
      "0.6613386613386614\n",
      "[7 8 1 ... 9 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6221\n",
      "\n",
      "Epoch # 17\n",
      "******************\n",
      "In accuracy\n",
      "[6 1 1 ... 0 5 5]\n",
      "[6 2 8 ... 0 5 5]\n",
      "0.6833166833166833\n",
      "[7 8 1 ... 4 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6196\n",
      "\n",
      "Epoch # 18\n",
      "******************\n",
      "In accuracy\n",
      "[8 1 1 ... 9 1 1]\n",
      "[8 1 1 ... 9 1 1]\n",
      "0.6633366633366633\n",
      "[7 2 1 ... 4 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6315\n",
      "\n",
      "Epoch # 19\n",
      "******************\n",
      "In accuracy\n",
      "[4 6 6 ... 0 3 9]\n",
      "[4 6 6 ... 0 5 9]\n",
      "0.6813186813186813\n",
      "[7 2 1 ... 9 3 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6372\n",
      "\n",
      "Epoch # 20\n",
      "******************\n",
      "In accuracy\n",
      "[3 4 0 ... 4 0 4]\n",
      "[3 7 0 ... 9 0 4]\n",
      "0.7052947052947053\n",
      "[7 2 1 ... 4 3 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6581\n",
      "\n",
      "Epoch # 21\n",
      "******************\n",
      "In accuracy\n",
      "[8 0 7 ... 5 4 9]\n",
      "[8 0 7 ... 3 7 9]\n",
      "0.7372627372627373\n",
      "[7 2 1 ... 9 3 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6794\n",
      "\n",
      "Epoch # 22\n",
      "******************\n",
      "In accuracy\n",
      "[7 1 1 ... 1 7 1]\n",
      "[7 1 1 ... 1 7 1]\n",
      "0.7192807192807192\n",
      "[7 2 1 ... 9 3 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6631\n",
      "\n",
      "Epoch # 23\n",
      "******************\n",
      "In accuracy\n",
      "[5 6 0 ... 4 4 5]\n",
      "[5 6 0 ... 4 4 5]\n",
      "0.7582417582417582\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6872\n",
      "\n",
      "Epoch # 24\n",
      "******************\n",
      "In accuracy\n",
      "[4 4 1 ... 1 1 4]\n",
      "[4 5 1 ... 7 1 4]\n",
      "0.7322677322677322\n",
      "[7 2 1 ... 4 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6726\n",
      "\n",
      "Epoch # 25\n",
      "******************\n",
      "In accuracy\n",
      "[1 8 0 ... 8 8 5]\n",
      "[1 8 0 ... 8 3 5]\n",
      "0.7742257742257742\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.6908\n",
      "\n",
      "Epoch # 26\n",
      "******************\n",
      "In accuracy\n",
      "[2 2 5 ... 1 0 5]\n",
      "[2 2 5 ... 2 9 5]\n",
      "0.7742257742257742\n",
      "[7 2 1 ... 9 3 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7063\n",
      "\n",
      "Epoch # 27\n",
      "******************\n",
      "In accuracy\n",
      "[9 3 3 ... 3 1 1]\n",
      "[4 3 3 ... 5 1 1]\n",
      "0.7772227772227772\n",
      "[7 2 1 ... 9 3 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7075\n",
      "\n",
      "Epoch # 28\n",
      "******************\n",
      "In accuracy\n",
      "[1 7 6 ... 6 1 5]\n",
      "[1 7 6 ... 6 2 5]\n",
      "0.7992007992007992\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7195\n",
      "\n",
      "Epoch # 29\n",
      "******************\n",
      "In accuracy\n",
      "[1 6 4 ... 4 9 1]\n",
      "[1 6 4 ... 4 9 1]\n",
      "0.7912087912087912\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7237\n",
      "\n",
      "Epoch # 30\n",
      "******************\n",
      "In accuracy\n",
      "[8 4 0 ... 4 4 0]\n",
      "[8 4 0 ... 9 4 0]\n",
      "0.7912087912087912\n",
      "[7 2 1 ... 9 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.728\n",
      "\n",
      "Epoch # 31\n",
      "******************\n",
      "In accuracy\n",
      "[2 6 1 ... 1 1 0]\n",
      "[2 6 1 ... 1 1 0]\n",
      "0.7932067932067932\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.726\n",
      "\n",
      "Epoch # 32\n",
      "******************\n",
      "In accuracy\n",
      "[0 4 6 ... 9 9 9]\n",
      "[0 4 6 ... 4 7 9]\n",
      "0.8131868131868132\n",
      "[7 2 1 ... 9 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7374\n",
      "\n",
      "Epoch # 33\n",
      "******************\n",
      "In accuracy\n",
      "[7 9 2 ... 5 5 6]\n",
      "[7 5 2 ... 5 5 6]\n",
      "0.8191808191808192\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7405\n",
      "\n",
      "Epoch # 34\n",
      "******************\n",
      "In accuracy\n",
      "[0 8 4 ... 2 8 8]\n",
      "[0 8 9 ... 2 8 8]\n",
      "0.8181818181818182\n",
      "[7 2 1 ... 9 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7365\n",
      "\n",
      "Epoch # 35\n",
      "******************\n",
      "In accuracy\n",
      "[9 7 9 ... 4 1 5]\n",
      "[9 7 8 ... 4 1 5]\n",
      "0.8291708291708292\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7395\n",
      "\n",
      "Epoch # 36\n",
      "******************\n",
      "In accuracy\n",
      "[0 0 3 ... 8 6 3]\n",
      "[0 0 3 ... 8 6 3]\n",
      "0.8201798201798202\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7442\n",
      "\n",
      "Epoch # 37\n",
      "******************\n",
      "In accuracy\n",
      "[6 4 4 ... 9 6 0]\n",
      "[6 4 4 ... 9 6 0]\n",
      "0.8511488511488512\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7571\n",
      "\n",
      "Epoch # 38\n",
      "******************\n",
      "In accuracy\n",
      "[2 9 8 ... 7 2 2]\n",
      "[2 4 8 ... 7 2 2]\n",
      "0.8471528471528471\n",
      "[7 2 1 ... 9 8 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.754\n",
      "\n",
      "Epoch # 39\n",
      "******************\n",
      "In accuracy\n",
      "[8 2 9 ... 8 7 9]\n",
      "[8 5 9 ... 8 7 9]\n",
      "0.8531468531468531\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7612\n",
      "\n",
      "Epoch # 40\n",
      "******************\n",
      "In accuracy\n",
      "[5 1 4 ... 5 7 7]\n",
      "[5 2 4 ... 3 7 7]\n",
      "0.8601398601398601\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7618\n",
      "\n",
      "Epoch # 41\n",
      "******************\n",
      "In accuracy\n",
      "[3 7 3 ... 8 8 1]\n",
      "[3 7 3 ... 8 8 1]\n",
      "0.8641358641358642\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7686\n",
      "\n",
      "Epoch # 42\n",
      "******************\n",
      "In accuracy\n",
      "[9 4 3 ... 3 2 3]\n",
      "[9 4 5 ... 3 2 3]\n",
      "0.8591408591408591\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7659\n",
      "\n",
      "Epoch # 43\n",
      "******************\n",
      "In accuracy\n",
      "[9 2 5 ... 9 2 3]\n",
      "[9 2 5 ... 4 2 3]\n",
      "0.8681318681318682\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7721\n",
      "\n",
      "Epoch # 44\n",
      "******************\n",
      "In accuracy\n",
      "[4 3 8 ... 4 1 2]\n",
      "[4 3 8 ... 4 1 2]\n",
      "0.8721278721278721\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7707\n",
      "\n",
      "Epoch # 45\n",
      "******************\n",
      "In accuracy\n",
      "[7 4 8 ... 9 3 7]\n",
      "[7 9 8 ... 4 3 7]\n",
      "0.8821178821178821\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7787\n",
      "\n",
      "Epoch # 46\n",
      "******************\n",
      "In accuracy\n",
      "[1 3 1 ... 8 1 2]\n",
      "[1 3 1 ... 5 1 2]\n",
      "0.8801198801198801\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.78\n",
      "\n",
      "Epoch # 47\n",
      "******************\n",
      "In accuracy\n",
      "[0 9 7 ... 7 7 2]\n",
      "[0 9 7 ... 7 7 2]\n",
      "0.8781218781218781\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7766\n",
      "\n",
      "Epoch # 48\n",
      "******************\n",
      "In accuracy\n",
      "[0 6 4 ... 3 6 3]\n",
      "[0 6 4 ... 5 6 3]\n",
      "0.8921078921078921\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7836\n",
      "\n",
      "Epoch # 49\n",
      "******************\n",
      "In accuracy\n",
      "[9 8 8 ... 2 0 6]\n",
      "[4 8 8 ... 2 0 6]\n",
      "0.8891108891108891\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7848\n",
      "\n",
      "Epoch # 50\n",
      "******************\n",
      "In accuracy\n",
      "[8 7 6 ... 6 7 6]\n",
      "[8 7 2 ... 6 9 6]\n",
      "0.8971028971028971\n",
      "[7 2 1 ... 9 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "0.7893\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    training_data, test_data = readData()\n",
    "    neural_network = NeuralNetwork(epochs = 50, alpha = 0.1, batch_size = 10, hidden_layers = 1, neurons = 5)\n",
    "    neural_network.init_data(training_data, test_data)\n",
    "    neural_network.algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b28ac761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6335d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9995  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "9996  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "9997  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "9998  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "9999  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      782  783  label  \n",
       "0       0    0      7  \n",
       "1       0    0      2  \n",
       "2       0    0      1  \n",
       "3       0    0      0  \n",
       "4       0    0      4  \n",
       "...   ...  ...    ...  \n",
       "9995    0    0      2  \n",
       "9996    0    0      3  \n",
       "9997    0    0      4  \n",
       "9998    0    0      5  \n",
       "9999    0    0      6  \n",
       "\n",
       "[10000 rows x 785 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a790f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = 'train_image.csv'\n",
    "training_label = 'train_label.csv'\n",
    "test_image = 'test_image.csv'\n",
    "test_label = 'test_label.csv'\n",
    "\n",
    "df = pd.read_csv(training_image, header=None)\n",
    "df['label'] = pd.read_csv(training_label, header=None)\n",
    "df = df.loc[0:9999]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bb2e5f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "7995  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "7996  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "7997  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "7998  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "7999  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      782  783  label  \n",
       "0       0    0      6  \n",
       "1       0    0      5  \n",
       "2       0    0      5  \n",
       "3       0    0      2  \n",
       "4       0    0      1  \n",
       "...   ...  ...    ...  \n",
       "7995    0    0      4  \n",
       "7996    0    0      0  \n",
       "7997    0    0      3  \n",
       "7998    0    0      2  \n",
       "7999    0    0      6  \n",
       "\n",
       "[8000 rows x 785 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6745042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
